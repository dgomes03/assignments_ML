{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dgomes03/assignments_ML/blob/main/Assignment2_Diogo_Gomes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43b639ef-88b4-4f18-af80-9f4bb9bfcae4",
      "metadata": {
        "id": "43b639ef-88b4-4f18-af80-9f4bb9bfcae4"
      },
      "source": [
        "# Machine Learning - Assignment 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9f1bacc-1297-4666-b57c-44713d35a089",
      "metadata": {
        "id": "e9f1bacc-1297-4666-b57c-44713d35a089"
      },
      "source": [
        "**Diogo Gomes nº26843**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43fbf843-be49-4531-ac16-a8299fa00f8c",
      "metadata": {
        "id": "43fbf843-be49-4531-ac16-a8299fa00f8c"
      },
      "source": [
        "Consider the time series data set 'aquifer_time_series.csv' available at https://github.com/isa-ulisboa/greends-pml/tree/main/data with the following columns:\n",
        "\n",
        "- 'date', in format DD/MM/YYYY\n",
        "- 'rainfall_mm', precipitation in mm\n",
        "- 'depth_to_groundwater_m', response variable (meters)\n",
        "- 'temperature_C', temperature in Celsius\n",
        "- 'drainage_m3', estimated drainage volume (cubic meters)\n",
        "- 'river_hydrometry_m', river level height (meters)\n",
        "\n",
        "The goal is to predict the value of 'depth_to_groundwater_m' for month K from the values of all variables at months K, K-1, ..., K-12 (except 'depth_to_groundwater_m' for month K, of course). Towards that end, it is recommended to preprocess the data in order to create a single value per month for each attribute (for instance using the median of the values for each attribute over each month).\n",
        "\n",
        "This regression problem involves time series, so cross-validation has to be done using groups to guarantee that folds are not correlated.\n",
        "\n",
        "You should create and fit a model (including preprocessing) for prediction. The code should be modular with a short main function. You should include in your script cross_val_score and StratifiedGroupKFold or GroupKFold, or some equivalent functionality.  For the regressor model you can use RandomForestRegressor.\n",
        "\n",
        "You need to create a video (maximum 3'-5' ) where you describe your script and the results you obtained, where you should include an actual vs predicted plot. You should edit the video to include the following keywords as text over the video when you describe them. The 9 keywords to address are:  model input size, model output size, preprocessing, scaling, model, predict, cross-validation folds, cross-validation groups and evaluation metric.\n",
        "\n",
        "Please submit the video (max 3'-5'), the URL of your notebook in your Github repository. One should be able to execute the code on Colab just by clicking the \"Open in Colab\" button and executing the notebook (see, for example, https://github.com/isa-ulisboa/greends-pml/blob/main/notebooks/iris_LM_inference.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "cf3e5334-ca30-4df4-b09f-281eb2ccfb97",
      "metadata": {
        "id": "cf3e5334-ca30-4df4-b09f-281eb2ccfb97",
        "outputId": "b0787737-b99f-4ce2-d06f-4bf6fba381c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/Users/diogogomes/Documents/Uni/Machine Learning/Assignments/2/aquifer_time_series.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f03fa1fa6ebc>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/diogogomes/Documents/Uni/Machine Learning/Assignments/2/aquifer_time_series.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/diogogomes/Documents/Uni/Machine Learning/Assignments/2/aquifer_time_series.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import GroupKFold, cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "df = pd.read_csv('/Users/diogogomes/Documents/Uni/Machine Learning/Assignments/2/aquifer_time_series.csv')\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e83192e-4f70-46b7-95dd-f6ea0d6e0be4",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "0e83192e-4f70-46b7-95dd-f6ea0d6e0be4"
      },
      "source": [
        "### Exploring the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0edea696-c247-4e48-bca2-1240c5ce34b8",
      "metadata": {
        "id": "0edea696-c247-4e48-bca2-1240c5ce34b8"
      },
      "outputs": [],
      "source": [
        "# Set up 2x3 subplot grid\n",
        "fig, axes = plt.subplots(2, 3, figsize=(14, 8))\n",
        "\n",
        "# List of columns to plot\n",
        "columns = [\n",
        "    'depth_to_groundwater_m',\n",
        "    'temperature_C',\n",
        "    'drainage_m3',\n",
        "    'river_hydrometry_m',\n",
        "    'rainfall_mm'\n",
        "]\n",
        "\n",
        "# Plot each variable\n",
        "for ax, col in zip(axes.flat, columns):\n",
        "    sns.scatterplot(x='date', y=col, data=df, ax=ax)\n",
        "    ax.set_title(col)\n",
        "    ax.tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Hide the unused subplot\n",
        "axes[1, 2].set_visible(False)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82709780-dd24-4a05-993c-ff7b4eec038d",
      "metadata": {
        "id": "82709780-dd24-4a05-993c-ff7b4eec038d"
      },
      "outputs": [],
      "source": [
        "# Initialize a new DataFrame for normalized data\n",
        "normalized_df = pd.DataFrame()\n",
        "normalized_df['date'] = df['date']\n",
        "\n",
        "# Normalize each column, ignoring NaNs and zeros\n",
        "for col in columns:\n",
        "    col_data = df[col]\n",
        "    valid = (col_data != 0) & (col_data.notna())\n",
        "    min_val = col_data[valid].min()\n",
        "    max_val = col_data[valid].max()\n",
        "\n",
        "    # Normalize only valid values; others become NaN\n",
        "    normalized = (col_data - min_val) / (max_val - min_val)\n",
        "    normalized[~valid] = None  # Set invalid entries to NaN\n",
        "\n",
        "    normalized_df[col] = normalized\n",
        "\n",
        "# Melt the dataframe for plotting\n",
        "melted_df = normalized_df.melt(id_vars='date', value_vars=columns,\n",
        "                                var_name='variable', value_name='value')\n",
        "\n",
        "# Drop NaNs (from originally missing or zero values)\n",
        "melted_df.dropna(inplace=True)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(14, 6))\n",
        "sns.lineplot(data=melted_df, x='date', y='value', hue='variable')\n",
        "\n",
        "plt.title('Normalized Variables Over Time (Excluding 0 and NaN)')\n",
        "plt.ylabel('Normalized Value (0 to 1)')\n",
        "plt.xticks(rotation=90)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "185c0554-7223-4fc5-968b-f9e819859fec",
      "metadata": {
        "id": "185c0554-7223-4fc5-968b-f9e819859fec"
      },
      "outputs": [],
      "source": [
        "# Convert date column to datetime\n",
        "df['date'] = pd.to_datetime(df['date'], format='%d/%m/%Y')\n",
        "\n",
        "# Extract year-month for grouping\n",
        "df['month'] = df['date'].dt.to_period('M')\n",
        "\n",
        "# Columns to normalize and plot\n",
        "columns = [\n",
        "    'depth_to_groundwater_m',\n",
        "    'temperature_C',\n",
        "    'drainage_m3',\n",
        "    'river_hydrometry_m',\n",
        "    'rainfall_mm'\n",
        "]\n",
        "\n",
        "# Exclude 0 and NaN, then calculate monthly means\n",
        "clean_df = df.copy()\n",
        "for col in columns:\n",
        "    clean_df[col] = clean_df[col].where((clean_df[col] != 0) & (clean_df[col].notna()), pd.NA)\n",
        "\n",
        "monthly_mean = clean_df.groupby('month')[columns].mean().reset_index()\n",
        "monthly_mean['month'] = monthly_mean['month'].dt.to_timestamp()\n",
        "\n",
        "# Normalize each column independently\n",
        "normalized_df = monthly_mean.copy()\n",
        "for col in columns:\n",
        "    col_data = monthly_mean[col]\n",
        "    min_val = col_data.min()\n",
        "    max_val = col_data.max()\n",
        "    normalized_df[col] = (col_data - min_val) / (max_val - min_val)\n",
        "\n",
        "# Melt for Seaborn plotting\n",
        "melted = normalized_df.melt(id_vars='month', value_vars=columns, var_name='variable', value_name='value')\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(14, 6))\n",
        "sns.lineplot(data=melted, x='month', y='value', hue='variable')\n",
        "\n",
        "plt.title('Monthly Normalized Trends (Excluding 0 and NaN)')\n",
        "plt.ylabel('Normalized Value (0 to 1)')\n",
        "plt.xlabel('Month')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9df4826a-10cd-4553-b10f-bec424027ef5",
      "metadata": {
        "id": "9df4826a-10cd-4553-b10f-bec424027ef5"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcfe5d7c",
      "metadata": {
        "id": "bcfe5d7c"
      },
      "outputs": [],
      "source": [
        "def load_and_preprocess_data(filepath):\n",
        "    df = pd.read_csv(filepath, parse_dates=['date'], dayfirst=True)\n",
        "    df['year_month'] = df['date'].dt.to_period('M')\n",
        "    # substituir 0s por NaNs nas colunas necessárias uma vez que os 0 nao signficam na verdade 0 mas sim nan.\n",
        "    cols_to_clean = ['river_hydrometry_m', 'drainage_m3', 'depth_to_groundwater_m']\n",
        "    df[cols_to_clean] = df[cols_to_clean].replace(0, np.nan)\n",
        "    monthly = df.groupby('year_month').median().reset_index()\n",
        "    return monthly"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7b1721e",
      "metadata": {
        "id": "a7b1721e"
      },
      "source": [
        "### Lag features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df606b08",
      "metadata": {
        "id": "df606b08"
      },
      "outputs": [],
      "source": [
        "def create_lag_features(df, n_lags=12):\n",
        "    lagged_data = pd.DataFrame()\n",
        "    feature_cols = [col for col in df.columns if col not in ['year_month', 'depth_to_groundwater_m']]\n",
        "\n",
        "    for col in feature_cols:\n",
        "        for lag in range(0, n_lags + 1):\n",
        "            lagged_data[f'{col}_lag_{lag}'] = df[col].shift(lag)\n",
        "\n",
        "    lagged_data['target'] = df['depth_to_groundwater_m']\n",
        "    lagged_data['group'] = np.arange(len(lagged_data))\n",
        "    lagged_data['date'] = df['year_month'].dt.to_timestamp()\n",
        "    lagged_data = lagged_data.dropna()\n",
        "    return lagged_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0104a20a",
      "metadata": {
        "id": "0104a20a"
      },
      "source": [
        "### Train and evaluate results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a3fe641",
      "metadata": {
        "id": "8a3fe641"
      },
      "outputs": [],
      "source": [
        "def build_model():\n",
        "    model = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('regressor', RandomForestRegressor(random_state=42))\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def plot_scatter_actual_vs_predicted(y_true, y_pred):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.scatter(y_true, y_pred, alpha=0.5, color='teal')\n",
        "    plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--', lw=2, label='Ideal Line')\n",
        "    plt.xlabel('Actual Values')\n",
        "    plt.ylabel('Predicted Values')\n",
        "    plt.title('Scatter Plot: Actual vs Predicted Values')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_actual_vs_predicted_over_time(dates, y_true, y_pred):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(dates, y_true, label='Actual Values', color='blue', alpha=0.7)\n",
        "    plt.plot(dates, y_pred, label='Predicted Values', color='red', alpha=0.7)\n",
        "    plt.title('Actual vs Predicted Values Over Time')\n",
        "    plt.xlabel('Date')\n",
        "    plt.xlim(pd.to_datetime('2009-12-31'), pd.to_datetime('2021-01-01'))\n",
        "    plt.xticks(pd.date_range(start='2009-12-31', end='2021-12-31', freq='YE'), rotation=45)\n",
        "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
        "    plt.ylabel('Depth to Groundwater (m)')\n",
        "    plt.ylim(-35, 0)\n",
        "    plt.yticks(np.arange(-35, 1, 5))\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def main():\n",
        "    filepath = '/Users/diogogomes/Documents/Uni/Machine Learning/Assignments/2/aquifer_time_series.csv'\n",
        "    monthly_data = load_and_preprocess_data(filepath)\n",
        "\n",
        "    data = create_lag_features(monthly_data)\n",
        "\n",
        "    # definir X e y (model input e output)\n",
        "    X = data.drop(columns=['target', 'group', 'date'])\n",
        "    y = data['target']\n",
        "    groups = data['group']\n",
        "    dates = data['date']\n",
        "\n",
        "    X = X.select_dtypes(include=[np.number])\n",
        "\n",
        "    model = build_model()\n",
        "\n",
        "    # Cross-validation\n",
        "    cv = GroupKFold(n_splits=5)\n",
        "    scores = cross_val_score(model, X, y, groups=groups, cv=cv, scoring='neg_mean_squared_error')\n",
        "    print(\"Cross-validation MSE scores:\", -scores)\n",
        "    print(\"Mean MSE:\", -scores.mean())\n",
        "\n",
        "    # treinar modelo no dataset todo\n",
        "    model.fit(X, y)\n",
        "\n",
        "    # fazer predict\n",
        "    y_pred = model.predict(X)\n",
        "\n",
        "    # plots\n",
        "    plot_scatter_actual_vs_predicted(y, y_pred)\n",
        "    plot_actual_vs_predicted_over_time(dates, y, y_pred)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}